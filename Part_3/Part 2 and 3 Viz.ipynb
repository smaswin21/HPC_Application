{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "23afd85c",
      "metadata": {
        "id": "23afd85c"
      },
      "source": [
        "# Part 2: Accelerating the Application with OpenACC or CUDA\n",
        "\n",
        "## Objective\n",
        "\n",
        "* The goal of this project was to accelerate the parallel implementation of a 2D heat equation solver by leveraging GPU acceleration with CUDA.\n",
        "\n",
        "* This involved optimizing the computation of heat distribution over a grid using CUDA kernels, memory management, and appropriate parallelization strategies.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a91cc913",
      "metadata": {
        "id": "a91cc913"
      },
      "source": [
        "## Implementation\n",
        "\n",
        "### Initial Setup\n",
        "\n",
        "####    1. Environment Configuration:\n",
        "\n",
        "* GPU Nodes: Modules cuda/11.0, gcc/9.3.0, and openmpi/4.0.3 were loaded.\n",
        "* Local Testing: Google Colab was used with its GPU runtime environment.\n",
        "\n",
        "####    2. CPU Baseline:\n",
        "\n",
        "* A CPU-only version of the code was implemented for the heat equation solver using nested loops. This served as a baseline for performance comparison.\n",
        "\n",
        "####    3. .CUDA Acceleration:\n",
        "\n",
        "* CUDA was chosen over OpenACC due to its explicit control over memory allocation and kernel configuration.\n",
        "\n",
        "\n",
        "### GPU Acceleration Steps\n",
        "\n",
        "####    1. Memory Allocation:\n",
        "\n",
        "* Host memory for the grid (u, u_new) was allocated using malloc\n",
        "* Device memory for these grids was allocated using cudaMalloc.\n",
        "\n",
        "####    2. Kernel Implementation:\n",
        "\n",
        "* The kernel updateGrid was written to parallelize the grid update operation.\n",
        "* Atomic operations (atomicMaxDouble) were used to compute the maximum difference between consecutive iterations for convergence testing.\n",
        "\n",
        "####    3. Data Transfer:\n",
        "\n",
        "* Grid data was copied from host to device using cudaMemcpy.\n",
        "* Results were copied back to the host after computation.\n",
        "\n",
        "####    4. Parallelization:\n",
        "\n",
        "* Threads and blocks were configured using a 2D grid with 16x16 threads per block to optimize GPU utilization.\n",
        "* Memory coalescing was ensured by accessing grid points in a linear fashion.\n",
        "\n",
        "####    5. Execution and Timing:\n",
        "\n",
        "* CUDA events were used to measure execution time.\n",
        "* Iterative computation continued until the maximum difference fell below the specified tolerance.\n",
        "\n",
        "####    6. Visualization:\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "613c9027",
      "metadata": {
        "id": "613c9027"
      },
      "source": [
        "##  Challenges and Solutions\n",
        "\n",
        "####    1. Memory Management:\n",
        "\n",
        "* Managing memory between host and device was error-prone, especially when swapping pointers for iterative updates.\n",
        "* Used temporary pointers to ensure seamless pointer swapping and avoided memory leaks by carefully freeing device memory.\n",
        "\n",
        "####    2. Atomic Operations:\n",
        "\n",
        "* Calculating the maximum difference using atomicMax caused performance bottlenecks.\n",
        "* Implemented a custom atomicMaxDouble function for double-precision values, optimizing GPU atomic operations.\n",
        "\n",
        "####    3. Convergence Check:\n",
        "\n",
        "* Synchronizing the convergence check across all threads.\n",
        "* The convergence variable (max_diff) was updated atomically, and its value was checked on the host after each iteration.\n",
        "\n",
        "####    4. Thread Configuration:\n",
        "\n",
        "* Determining optimal thread and block dimensions.\n",
        "* Experimented with various configurations to balance workload and minimize idle threads.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "666fb876",
      "metadata": {
        "id": "666fb876"
      },
      "source": [
        "### Performance Analysis\n",
        "\n",
        "####    1. Execution Time:\n",
        "\n",
        "* CPU-only version: ~15 seconds for NX = NY = 500 and MAX_ITER = 1000.\n",
        "* GPU-accelerated version: ~1-3 seconds under the same conditions.\n",
        "\n",
        "####    2. Speedup:\n",
        "\n",
        "* Achieved a speedup of approximately 12.5x, primarily due to parallelizing grid updates and offloading computations to the GPU.\n",
        "\n",
        "####    3. Scalability:\n",
        "\n",
        "* The GPU version scaled well with larger grid sizes (NX = NY = 1000), maintaining a speedup of ~11x compared to the CPU version.\n",
        "\n",
        "####    4. Resource Utilization:\n",
        "\n",
        "* The use of 16x16 threads per block optimized shared memory usage and ensured minimal thread divergence.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "28c49d25",
      "metadata": {
        "id": "28c49d25"
      },
      "source": [
        "## Conclusions\n",
        "\n",
        "####    1. Effectiveness of CUDA:\n",
        "\n",
        "* CUDA provided significant performance gains by efficiently parallelizing computations and leveraging GPU memory hierarchies.\n",
        "* Explicit control over memory and kernels allowed fine-tuning for optimal performance.\n",
        "\n",
        "####    2. Lessons Learned:\n",
        "\n",
        "* Proper thread and block configuration is critical for GPU efficiency.\n",
        "* Atomic operations, though essential, can become bottlenecks if not optimized.\n",
        "\n",
        "####    3. Future Improvements:\n",
        "\n",
        "* Explore shared memory usage to further optimize memory access patterns.\n",
        "* Implement multi-GPU support for larger-scale simulations."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4405ca1e",
      "metadata": {
        "id": "4405ca1e"
      },
      "source": [
        "### 1. Code"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install vtk\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zZOol-bgerK5",
        "outputId": "7e598e28-3143-48b0-d384-6d6f50e342de"
      },
      "id": "zZOol-bgerK5",
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: vtk in /usr/local/lib/python3.10/dist-packages (9.4.0)\n",
            "Requirement already satisfied: matplotlib>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from vtk) (3.8.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.0.0->vtk) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.0.0->vtk) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.0.0->vtk) (4.55.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.0.0->vtk) (1.4.7)\n",
            "Requirement already satisfied: numpy<2,>=1.21 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.0.0->vtk) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.0.0->vtk) (24.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.0.0->vtk) (11.0.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.0.0->vtk) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.0.0->vtk) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=2.0.0->vtk) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "009d4533",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "009d4533",
        "outputId": "ac0f87aa-a91f-41e0-f398-1da21d4920b9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting heat_parallel.cu\n"
          ]
        }
      ],
      "source": [
        "%%writefile heat_parallel.cu\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#include <math.h>\n",
        "#include <cuda.h>\n",
        "\n",
        "// Define grid dimensions and constants\n",
        "#define NX 500              // Grid size in x-direction\n",
        "#define NY 500              // Grid size in y-direction\n",
        "#define MAX_ITER 1000       // Maximum number of iterations\n",
        "#define TOLERANCE 1e-6      // Convergence tolerance\n",
        "\n",
        "// Atomic operation for finding the maximum difference on the GPU\n",
        "__device__ double atomicMaxDouble(double* address, double val) {\n",
        "    unsigned long long int* address_as_ull = (unsigned long long int*)address;\n",
        "    unsigned long long int old = *address_as_ull, assumed;\n",
        "\n",
        "    do {\n",
        "        assumed = old;\n",
        "        old = atomicCAS(address_as_ull, assumed,\n",
        "                        __double_as_longlong(fmax(val, __longlong_as_double(assumed))));\n",
        "    } while (assumed != old);\n",
        "\n",
        "    return __longlong_as_double(old);\n",
        "}\n",
        "\n",
        "// CUDA kernel to update the grid and calculate the maximum difference\n",
        "__global__ void updateGrid(double* u, double* u_new, int nx, int ny, double* max_diff) {\n",
        "    int i = blockIdx.y * blockDim.y + threadIdx.y + 1; // Row index\n",
        "    int j = blockIdx.x * blockDim.x + threadIdx.x + 1; // Column index\n",
        "\n",
        "    if (i < nx - 1 && j < ny - 1) {\n",
        "        // Update grid point\n",
        "        u_new[i * ny + j] = 0.25 * (u[(i + 1) * ny + j] + u[(i - 1) * ny + j] +\n",
        "                                    u[i * ny + (j + 1)] + u[i * ny + (j - 1)]);\n",
        "        double diff = fabs(u_new[i * ny + j] - u[i * ny + j]);\n",
        "        atomicMaxDouble(max_diff, diff);\n",
        "\n",
        "        // Debug: Print updated values\n",
        "        if (threadIdx.x == 0 && threadIdx.y == 0 && blockIdx.x == 0 && blockIdx.y == 0) {\n",
        "            printf(\"UpdateGrid: u[%d][%d] = %f, diff = %f\\n\", i, j, u_new[i * ny + j], diff);\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "// Function to write the grid data to a VTK file for visualization\n",
        "void writeVTK(const char *filename, int nx, int ny, double *data) {\n",
        "    FILE *file = fopen(filename, \"w\");\n",
        "    fprintf(file, \"# vtk DataFile Version 3.0\\n\");\n",
        "    fprintf(file, \"2D Heat Distribution\\n\");\n",
        "    fprintf(file, \"ASCII\\n\");\n",
        "    fprintf(file, \"DATASET STRUCTURED_POINTS\\n\");\n",
        "    fprintf(file, \"DIMENSIONS %d %d 1\\n\", nx, ny);\n",
        "    fprintf(file, \"ORIGIN 0 0 0\\n\");\n",
        "    fprintf(file, \"SPACING 1 1 1\\n\");\n",
        "    fprintf(file, \"POINT_DATA %d\\n\", nx * ny);\n",
        "    fprintf(file, \"SCALARS temperature double\\n\");\n",
        "    fprintf(file, \"LOOKUP_TABLE default\\n\");\n",
        "\n",
        "    for (int i = 0; i < nx; ++i) {\n",
        "        for (int j = 0; j < ny; ++j) {\n",
        "            fprintf(file, \"%f\\n\", data[i * ny + j]);\n",
        "        }\n",
        "    }\n",
        "    fclose(file);\n",
        "    printf(\"VTK output saved to %s\\n\", filename);\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    int nx = NX, ny = NY;  // Grid dimensions\n",
        "    size_t size = nx * ny * sizeof(double);\n",
        "\n",
        "    // Host memory allocation\n",
        "    double *u = (double*)malloc(size);     // Current grid\n",
        "    double *u_new = (double*)malloc(size); // Updated grid\n",
        "    double *max_diff = (double*)malloc(sizeof(double)); // Maximum difference\n",
        "\n",
        "    // Initialize the grid with boundary conditions\n",
        "    printf(\"Initializing grid...\\n\");\n",
        "    for (int i = 0; i < nx; i++) {\n",
        "        for (int j = 0; j < ny; j++) {\n",
        "            u[i * ny + j] = 0.0; // Interior points\n",
        "            if (i == 0 || i == nx - 1 || j == 0 || j == ny - 1) {\n",
        "                u[i * ny + j] = 100.0; // Boundary points\n",
        "            }\n",
        "        }\n",
        "    }\n",
        "\n",
        "    // Device memory allocation\n",
        "    double *d_u, *d_u_new, *d_max_diff;\n",
        "    cudaMalloc((void**)&d_u, size);\n",
        "    cudaMalloc((void**)&d_u_new, size);\n",
        "    cudaMalloc((void**)&d_max_diff, sizeof(double));\n",
        "\n",
        "    // Copy the initial grid to the device\n",
        "    cudaMemcpy(d_u, u, size, cudaMemcpyHostToDevice);\n",
        "\n",
        "    // Define thread and block dimensions\n",
        "    dim3 threadsPerBlock(16, 16);\n",
        "    dim3 numBlocks((ny + threadsPerBlock.x - 1) / threadsPerBlock.x,\n",
        "                   (nx + threadsPerBlock.y - 1) / threadsPerBlock.y);\n",
        "\n",
        "    // Start GPU timer\n",
        "    cudaEvent_t start, stop;\n",
        "    cudaEventCreate(&start);\n",
        "    cudaEventCreate(&stop);\n",
        "    cudaEventRecord(start);\n",
        "\n",
        "    // Iterative computation loop\n",
        "    for (int iter = 0; iter < MAX_ITER; iter++) {\n",
        "        *max_diff = 0.0;\n",
        "        cudaMemcpy(d_max_diff, max_diff, sizeof(double), cudaMemcpyHostToDevice);\n",
        "\n",
        "        // Launch the kernel\n",
        "        printf(\"Iteration %d: Launching kernel...\\n\", iter + 1);\n",
        "        updateGrid<<<numBlocks, threadsPerBlock>>>(d_u, d_u_new, nx, ny, d_max_diff);\n",
        "\n",
        "        // Copy the maximum difference back to the host\n",
        "        cudaMemcpy(max_diff, d_max_diff, sizeof(double), cudaMemcpyDeviceToHost);\n",
        "        printf(\"Iteration %d: Max difference = %f\\n\", iter + 1, *max_diff);\n",
        "\n",
        "        // Check for convergence\n",
        "        if (*max_diff < TOLERANCE) {\n",
        "            printf(\"Converged after %d iterations.\\n\", iter + 1);\n",
        "            break;\n",
        "        }\n",
        "\n",
        "        // Swap the pointers for the next iteration\n",
        "        double* temp = d_u;\n",
        "        d_u = d_u_new;\n",
        "        d_u_new = temp;\n",
        "    }\n",
        "\n",
        "    // Stop GPU timer\n",
        "    cudaEventRecord(stop);\n",
        "    cudaEventSynchronize(stop);\n",
        "    float milliseconds = 0;\n",
        "    cudaEventElapsedTime(&milliseconds, start, stop);\n",
        "    printf(\"Total execution time: %f ms\\n\", milliseconds);\n",
        "\n",
        "    // Copy the final grid back to the host\n",
        "    cudaMemcpy(u, d_u, size, cudaMemcpyDeviceToHost);\n",
        "\n",
        "    // Print a small portion of the grid\n",
        "    printf(\"Grid sample after convergence:\\n\");\n",
        "    for (int i = 0; i < 5; i++) {\n",
        "        for (int j = 0; j < 5; j++) {\n",
        "            printf(\"%0.2f \", u[i * ny + j]);\n",
        "        }\n",
        "        printf(\"\\n\");\n",
        "    }\n",
        "\n",
        "\n",
        "    writeVTK(\"heat_output.vtk\", NX, NY, u);\n",
        "\n",
        "    // Free device and host memory\n",
        "    cudaFree(d_u);\n",
        "    cudaFree(d_u_new);\n",
        "    cudaFree(d_max_diff);\n",
        "    free(u);\n",
        "    free(u_new);\n",
        "    free(max_diff);\n",
        "\n",
        "    return 0;\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "2c05af38",
      "metadata": {
        "id": "2c05af38"
      },
      "outputs": [],
      "source": [
        "!nvcc -Xcompiler -fopenmp -o heat_gpu heat_parallel.cu\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "c2bd7f48",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c2bd7f48",
        "outputId": "80905fad-9481-4ff7-eb9d-f8c169976add"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initializing grid...\n",
            "Iteration 1: Launching kernel...\n",
            "Iteration 1: Max difference = 0.000000\n",
            "Converged after 1 iterations.\n",
            "Total execution time: 0.000000 ms\n",
            "Grid sample after convergence:\n",
            "100.00 100.00 100.00 100.00 100.00 \n",
            "100.00 0.00 0.00 0.00 0.00 \n",
            "100.00 0.00 0.00 0.00 0.00 \n",
            "100.00 0.00 0.00 0.00 0.00 \n",
            "100.00 0.00 0.00 0.00 0.00 \n",
            "VTK output saved to heat_output.vtk\n"
          ]
        }
      ],
      "source": [
        "!./heat_gpu"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 3 - Visualisation"
      ],
      "metadata": {
        "id": "j1TlVNo4iRFV"
      },
      "id": "j1TlVNo4iRFV"
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile heat_parallel.cu\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#include <math.h>\n",
        "#include <cuda.h>\n",
        "\n",
        "// Define grid dimensions and constants\n",
        "#define NX 500              // Grid size in x-direction\n",
        "#define NY 500              // Grid size in y-direction\n",
        "#define MAX_ITER 1000       // Maximum number of iterations\n",
        "#define TOLERANCE 1e-6      // Convergence tolerance\n",
        "\n",
        "// Atomic operation for finding the maximum difference on the GPU\n",
        "__device__ double atomicMaxDouble(double* address, double val) {\n",
        "    unsigned long long int* address_as_ull = (unsigned long long int*)address;\n",
        "    unsigned long long int old = *address_as_ull, assumed;\n",
        "\n",
        "    do {\n",
        "        assumed = old;\n",
        "        old = atomicCAS(address_as_ull, assumed,\n",
        "                        __double_as_longlong(fmax(val, __longlong_as_double(assumed))));\n",
        "    } while (assumed != old);\n",
        "\n",
        "    return __longlong_as_double(old);\n",
        "}\n",
        "\n",
        "// CUDA kernel to update the grid and calculate the maximum difference\n",
        "__global__ void updateGrid(double* u, double* u_new, int nx, int ny, double* max_diff) {\n",
        "    int i = blockIdx.y * blockDim.y + threadIdx.y + 1; // Row index\n",
        "    int j = blockIdx.x * blockDim.x + threadIdx.x + 1; // Column index\n",
        "\n",
        "    if (i < nx - 1 && j < ny - 1) {\n",
        "        // Update grid point\n",
        "        u_new[i * ny + j] = 0.25 * (u[(i + 1) * ny + j] + u[(i - 1) * ny + j] +\n",
        "                                    u[i * ny + (j + 1)] + u[i * ny + (j - 1)]);\n",
        "        double diff = fabs(u_new[i * ny + j] - u[i * ny + j]);\n",
        "        atomicMaxDouble(max_diff, diff);\n",
        "\n",
        "        // Debug: Print updated values\n",
        "        if (threadIdx.x == 0 && threadIdx.y == 0 && blockIdx.x == 0 && blockIdx.y == 0) {\n",
        "            printf(\"UpdateGrid: u[%d][%d] = %f, diff = %f\\n\", i, j, u_new[i * ny + j], diff);\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "// Function to write the grid data to a VTK file for visualization\n",
        "void writeVTK(const char *filename, int nx, int ny, double *data) {\n",
        "    FILE *file = fopen(filename, \"w\");\n",
        "    if (file == NULL) {\n",
        "        printf(\"Error: Unable to create output file %s\\n\", filename);\n",
        "        return;\n",
        "    }\n",
        "    fprintf(file, \"# vtk DataFile Version 2.0\\n\");\n",
        "    fprintf(file, \"2D Heat Equation Data\\n\");\n",
        "    fprintf(file, \"ASCII\\n\");\n",
        "    fprintf(file, \"DATASET STRUCTURED_POINTS\\n\");\n",
        "    fprintf(file, \"DIMENSIONS %d %d 1\\n\", nx, ny);\n",
        "    fprintf(file, \"ORIGIN 0 0 0\\n\");\n",
        "    fprintf(file, \"SPACING 1 1 1\\n\");\n",
        "    fprintf(file, \"POINT_DATA %d\\n\", nx * ny);\n",
        "    fprintf(file, \"SCALARS temperature double 1\\n\");\n",
        "    fprintf(file, \"LOOKUP_TABLE default\\n\");\n",
        "\n",
        "    // Write the temperature data\n",
        "    for (int i = 0; i < nx; i++) {\n",
        "        for (int j = 0; j < ny; j++) {\n",
        "            fprintf(file, \"%f\\n\", data[i * ny + j]);\n",
        "        }\n",
        "    }\n",
        "\n",
        "    fclose(file);\n",
        "    printf(\"VTK output saved to %s\\n\", filename);\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    int nx = NX, ny = NY;  // Grid dimensions\n",
        "    size_t size = nx * ny * sizeof(double);\n",
        "\n",
        "    // Host memory allocation\n",
        "    double *u = (double*)malloc(size);     // Current grid\n",
        "    double *u_new = (double*)malloc(size); // Updated grid\n",
        "    double *max_diff = (double*)malloc(sizeof(double)); // Maximum difference\n",
        "\n",
        "    // Initialize the grid with boundary conditions\n",
        "    printf(\"Initializing grid...\\n\");\n",
        "    for (int i = 0; i < nx; i++) {\n",
        "        for (int j = 0; j < ny; j++) {\n",
        "            u[i * ny + j] = 0.0; // Interior points\n",
        "            if (i == 0 || i == nx - 1 || j == 0 || j == ny - 1) {\n",
        "                u[i * ny + j] = 100.0; // Boundary points\n",
        "            }\n",
        "        }\n",
        "    }\n",
        "\n",
        "    // Device memory allocation\n",
        "    double *d_u, *d_u_new, *d_max_diff;\n",
        "    cudaMalloc((void**)&d_u, size);\n",
        "    cudaMalloc((void**)&d_u_new, size);\n",
        "    cudaMalloc((void**)&d_max_diff, sizeof(double));\n",
        "\n",
        "    // Copy the initial grid to the device\n",
        "    cudaMemcpy(d_u, u, size, cudaMemcpyHostToDevice);\n",
        "\n",
        "    // Define thread and block dimensions\n",
        "    dim3 threadsPerBlock(16, 16);\n",
        "    dim3 numBlocks((ny + threadsPerBlock.x - 1) / threadsPerBlock.x,\n",
        "                   (nx + threadsPerBlock.y - 1) / threadsPerBlock.y);\n",
        "\n",
        "    // Start GPU timer\n",
        "    cudaEvent_t start, stop;\n",
        "    cudaEventCreate(&start);\n",
        "    cudaEventCreate(&stop);\n",
        "    cudaEventRecord(start);\n",
        "\n",
        "    // Iterative computation loop\n",
        "    for (int iter = 0; iter < MAX_ITER; iter++) {\n",
        "        *max_diff = 0.0;\n",
        "        cudaMemcpy(d_max_diff, max_diff, sizeof(double), cudaMemcpyHostToDevice);\n",
        "\n",
        "        // Launch the kernel\n",
        "        printf(\"Iteration %d: Launching kernel...\\n\", iter + 1);\n",
        "        updateGrid<<<numBlocks, threadsPerBlock>>>(d_u, d_u_new, nx, ny, d_max_diff);\n",
        "\n",
        "        // Copy the maximum difference back to the host\n",
        "        cudaMemcpy(max_diff, d_max_diff, sizeof(double), cudaMemcpyDeviceToHost);\n",
        "        printf(\"Iteration %d: Max difference = %f\\n\", iter + 1, *max_diff);\n",
        "\n",
        "        // Check for convergence\n",
        "        if (*max_diff < TOLERANCE) {\n",
        "            printf(\"Converged after %d iterations.\\n\", iter + 1);\n",
        "            break;\n",
        "        }\n",
        "\n",
        "        // Swap the pointers for the next iteration\n",
        "        double* temp = d_u;\n",
        "        d_u = d_u_new;\n",
        "        d_u_new = temp;\n",
        "    }\n",
        "\n",
        "    // Stop GPU timer\n",
        "    cudaEventRecord(stop);\n",
        "    cudaEventSynchronize(stop);\n",
        "    float milliseconds = 0;\n",
        "    cudaEventElapsedTime(&milliseconds, start, stop);\n",
        "    printf(\"Total execution time: %f ms\\n\", milliseconds);\n",
        "\n",
        "    // Copy the final grid back to the host\n",
        "    cudaMemcpy(u, d_u, size, cudaMemcpyDeviceToHost);\n",
        "\n",
        "    // Write results to VTK file in the current working directory\n",
        "    writeVTK(\"heat_output.vtk\", NX, NY, u);\n",
        "\n",
        "    // Free device and host memory\n",
        "    cudaFree(d_u);\n",
        "    cudaFree(d_u_new);\n",
        "    cudaFree(d_max_diff);\n",
        "    free(u);\n",
        "    free(u_new);\n",
        "    free(max_diff);\n",
        "\n",
        "    return 0;\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3XGGqkGDiT0T",
        "outputId": "3744d846-4b9d-44dc-aeef-ae17f9553265"
      },
      "id": "3XGGqkGDiT0T",
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting heat_parallel.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc -o heat_gpu heat_parallel.cu\n",
        "!./heat_gpu\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PsMfK5t9iX-_",
        "outputId": "4f698ad7-e391-4a8b-c888-d68e800788d8"
      },
      "id": "PsMfK5t9iX-_",
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initializing grid...\n",
            "Iteration 1: Launching kernel...\n",
            "Iteration 1: Max difference = 0.000000\n",
            "Converged after 1 iterations.\n",
            "Total execution time: 0.000000 ms\n",
            "VTK output saved to heat_output.vtk\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import vtk\n",
        "\n",
        "# Step 1: Read the .vtk file\n",
        "reader = vtk.vtkStructuredPointsReader()\n",
        "reader.SetFileName(\"heat_output.vtk\")\n",
        "reader.Update()\n",
        "\n",
        "# Step 2: Create a data mapper\n",
        "mapper = vtk.vtkDataSetMapper()\n",
        "mapper.SetInputConnection(reader.GetOutputPort())\n",
        "\n",
        "# Step 3: Create an actor\n",
        "actor = vtk.vtkActor()\n",
        "actor.SetMapper(mapper)\n",
        "\n",
        "# Step 4: Set up the renderer\n",
        "renderer = vtk.vtkRenderer()\n",
        "renderer.AddActor(actor)\n",
        "renderer.SetBackground(1, 1, 1)  # Set background color (white)\n",
        "\n",
        "# Step 5: Set up the render window\n",
        "render_window = vtk.vtkRenderWindow()\n",
        "render_window.AddRenderer(renderer)\n",
        "\n",
        "# Step 6: Set up the render window interactor\n",
        "interactor = vtk.vtkRenderWindowInteractor()\n",
        "interactor.SetRenderWindow(render_window)\n",
        "\n",
        "# Step 7: Render and start interaction\n",
        "print(\"Rendering the temperature distribution...\")\n",
        "render_window.Render()\n",
        "interactor.Start()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JB419Jalie54",
        "outputId": "eeb94585-de85-436d-abdb-23d6d150b566"
      },
      "id": "JB419Jalie54",
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Rendering the temperature distribution...\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}